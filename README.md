# M√©todos extra√ß√£o de outliers üìú
Neste reposit√≥rio, realizo a compara√ß√£o de diferentes m√©todos para a detec√ß√£o de outliers, incluindo IQR, Z-Core, Isolation Forest e KNN. Meu objetivo √© determinar qual desses m√©todos √© mais adequado para o tipo de distribui√ß√£o de dados em quest√£o.
Este an√°lises foi implementado em Python. üíº 

A detec√ß√£o de outliers √© uma etapa crucial na an√°lise de dados, pois esses valores at√≠picos podem distorcer significativamente as an√°lises estat√≠sticas e os resultados dos modelos preditivos. Portanto, comparar e selecionar o m√©todo mais eficaz para identificar e tratar esses outliers √© essencial para garantir a precis√£o e a confiabilidade das conclus√µes derivadas dos dados.

Cada m√©todo de detec√ß√£o de outliers possui suas pr√≥prias vantagens e limita√ß√µes, e a escolha do m√©todo mais apropriado depende da natureza dos dados e das caracter√≠sticas da distribui√ß√£o subjacente. Ao realizar essa compara√ß√£o, busco n√£o apenas identificar o m√©todo mais preciso, mas tamb√©m entender melhor as nuances dos dados e como diferentes m√©todos de detec√ß√£o de outliers podem ser aplicados de forma eficaz em diferentes contextos anal√≠ticos.

## O que s√£o Outliers e por que detect√°-los? üîñ
Um outlier √© uma observa√ß√£o que se diferencia tanto das demais observa√ß√µes que levanta suspeitas de que aquela observa√ß√£o foi gerada por um mecanismo distinto‚Äù (Hawkins, 1980)

Detectar outliers √© uma etapa crucial na an√°lise de dados, pois ajuda a garantir a integridade, precis√£o e confiabilidade das conclus√µes derivadas dos dados. A presen√ßa de outliers pode distorcer as an√°lises estat√≠sticas e os resultados dos modelos preditivos, influenciando negativamente as interpreta√ß√µes feitas a partir dos dados. Portanto, identificar e tratar esses valores at√≠picos de forma adequada √© fundamental para assegurar que as conclus√µes obtidas sejam v√°lidas e representativas do verdadeiro comportamento dos dados.

## Nossos dados: üîñ
Os dados cont√™m o tempo de atendimento (em dias) dos tickets da √°rea de suporte de uma empresa, divididos em L1 (layer 1) e L2 (layer 2). O Tempo Total de Suporte √© a soma dos tempos de L1 e L2, desde o ano de 2021 at√© 2024.


## Distribui√ß√£o dos dados: üîñ
No Fig 1, por meio do histograma visualizamos a distribui√ß√£o do nossos dados para L1, L2 e Suporte.
L1: Tempo de atendimento tem um range de 0 at√© 482 dias
L2: Tempo de atendimento tem um range de 0 at√© 349 dias
Suporte: Tempo de atendimento tem um range de 0 at√© 510 dias
<p align="center">
  <img src="https://drive.google.com/file/d/1utf1NEMJGrhyh7fp5mrKVqy7sLOVfdan/view?usp=sharing" width=80% height=80%>  

</p>

Na Fig2, por medio do gr√°fico de box plot podemos observar a presen√ßa de outliers (os pontos em preto).
<p align="center">
<img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/boxplot.png" width=80% height=80%>
</p

Na Figura 3, realizei os c√°lculos das estat√≠sticas e tanto em L1, L2 e Suporte podemos observar que a m√©dia √© maior que a mediana, o que indica que a distribui√ß√£o est√° inclinada para a direita (positivamente assim√©trica). A maioria dos dados encontra-se √† esquerda da m√©dia, isso tamb√©m √© poss√≠vel observar na Figura 1. Este tipo de distribui√ß√£o pode ser afetado por valores extremos.

No n√≠vel L2, o tempo m√©dio de atendimento √© ainda maior, em torno de 50.2 dias, com um desvio padr√£o de 59.9 dias. Isso indica uma variabilidade ainda maior nos tempos de atendimento em compara√ß√£o com o n√≠vel L1, c

√â evidente que os tempos de atendimento s√£o significativamente mais longos no n√≠vel L2 em compara√ß√£o com o n√≠vel L1. Isso sugere que as solicita√ß√µes de suporte nos n√≠veis L2 s√£o mais complexas ou exigem mais tempo para serem resolvidas do que as do n√≠vel L1.

<p align="center">
<img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/estatisticas-geral.JPG" width=80% height=80%>
</p>

# 1er M√©todo - Itervalo Interquartil 

Atrav√©s desse m√©todo, outliers s√£o definidos matematicamente como as observa√ß√µes que est√£o abaixo (Q1 ‚àí 1,5 x IQR) do "bigode inferior" do boxplot ou acima (Q3 + 1,5 x IQR) do "bigode superior" do boxplot.
<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/IQR.JPG" width=40% height=40%>  
</p>
Ap√≥s o c√°lculo dos limites superior e inferior, procedemos com a detec√ß√£o dos outliers, os pontos em vermelho, como pode ser observado na Figura 5.

<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/DetectionIQR.png" width=90% height=80%>  
</p>
Uma vez detectados os outliers, procedi com a remo√ß√£o dos mesmos. Portanto, √© poss√≠vel observar nosso histograma e as estat√≠sticas ap√≥s a aplica√ß√£o do 1¬∫ m√©todo nas Figuras 6 e 7.

<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/histo_1ermetodos.png" width=100% height=80%>  
   <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/estadisticas_1ermetodo.JPG" width=80% height=80%>  
</p>

##### Ao remover os outliers, observamos uma redu√ß√£o na variabilidade dos tempos de atendimento em todos os n√≠veis de suporte (L1, L2 e Suporte total). Isso √© evidenciado pela diminui√ß√£o dos desvios padr√£o em rela√ß√£o aos valores originais, o que sugere uma distribui√ß√£o dos dados mais concentrada em torno das medidas de tend√™ncia central.

##### Ao aplicar o m√©todo de Intervalo Interquartil para remover outliers, conseguimos melhorar a qualidade e a confiabilidade das an√°lises dos tempos de atendimento nos diferentes n√≠veis de suporte. Isso nos permite obter insights mais robustos e tomar decis√µes mais informadas para otimizar os processos de suporte e melhorar a experi√™ncia do cliente.

##### Como o m√©todo se concentra no quartil n√£o √© influenciado pela forma exacta da distribui√ß√£o.

# 2do M√©todo - Z_Core
O m√©todo Z-Score (ou escore Z) √© uma medida estat√≠stica que indica quantos desvios padr√£o um ponto de dados est√° da m√©dia 
de um conjunto de dados.

##### Z = (X ‚Äì Œº) / œÉ
‚Äì Œº √© a m√©dia do conjunto de dados

‚Äì œÉ √© o desvio padr√£o do conjunto de dados
<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/zcore.JPG" width=40% height=40%>  
</p>

Ap√≥s calcular a m√©dia e o desvio padr√£o, calculei os limites superior e inferior e procedi √† extra√ß√£o dos outliers. A distribui√ß√£o de dados ap√≥s a remo√ß√£o dos outliers pelo m√©todo Z-Core pode ser observada na Figura 8.

<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/histo_2dometodos.png" width=100% height=80%>  
 </p>

Ap√≥s aplicar o m√©todo Z-Core para remover outliers dos dados, foram identificados poucos outliers em compara√ß√£o com o primer m√©todo, ainda observamos uma alta variabilidade significativa nos tempos de atendimento em todos os niveis.
<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/estadisticas_2dometodo.JPG" width=80% height=80%>  
 </p>

##### Este m√©todo envolve a m√©dia e o desvio padr√£o, se houver outliers extremos, especialmente em distribui√ß√£o assim√©tricas como as que temos, pode afetar significativamente a estima√ß√£o dos parametros.
##### Este m√©todo e recomend√°vel em distribui√ß√µes normais.



# 3er M√©todo - Isolation Forest
O Isolation Forest √© um algoritmo de machine learning utilizado para detec√ß√£o de anomalias. Este modelo baseia-se na cria√ß√£o de parti√ß√µes recursivas nos dados, visando isolar as anomalias, assim como mostra a Fig 9, onde o outliers esta respresentando com o label Xj.

<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/IsolationForest.JPG" width=40% height=40%>  
</p>

Ap√≥s criar e treinar o modelo Isolation Forest da biblioteca scikit-learn, onde definimos o n√∫mero de √°rvores na floresta (n_estimators=100), √© poss√≠vel visualizar os pontos de outliers (em vermelho) na Figura 10.
<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/DetectionIsolationForest.png" width=90% height=80%>  
</p>

Uma vez detectados os outliers, procedi com a remo√ß√£o dos mesmos. Portanto, √© poss√≠vel observar nosso histograma e as estat√≠sticas ap√≥s a aplica√ß√£o do 3¬∫ m√©todo nas Figuras 11 e 12.
<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/histo_3ermetodos.png" width=100% height=80%>  
   <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/estadisticas_3ermetodo.JPG" width=80% height=80%>  
</p>

##### A extra√ß√£o de outliers usando o m√©todo de Isolation Forest mostram uma redu√ß√£o na variabilidade dos tempos de atendimento em todos os n√≠veis de suporte, indicando uma distribui√ß√£o mais homog√™nea dos dados
##### Este m√©todo de Isolation Forest √© conhecido por sua robustez a distribui√ß√µes assim√©tricas. Isso ocorre porque ele se baseia no princ√≠pio de isolar anomalias com base em sua raridade e n√£o em sua distribui√ß√£o. 

# 4to M√©todo - k-NN (k-Nearest Neighbors)
O m√©todo k-NN (k-Nearest Neighbors) √© uma t√©cnica de aprendizado de m√°quina que detecta anomalias com base na proximidade dos vizinhos mais pr√≥ximos. Ele calcula a dist√¢ncia entre cada ponto de dados e seus vizinhos mais pr√≥ximos, e considera um ponto como uma anomalia se estiver significativamente distante de seus vizinhos. Na Fig 13, podemos observar que os pontos em vermelho (outliers) est√£o londe de seus vizinhos pr√≥ximos, os pontos em azul.

<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/knn.png" width=40% height=40%>  
</p>

Ap√≥s criar e treinar o modelo k-NN da biblioteca scikit-learn, onde definimos o n√∫mero de vizinhos (n_neighbors=3), √© poss√≠vel visualizar os pontos de outliers (em vermelho) na Figura 14.
Verificamos que tem algunos meses que nossos dados s√£o mais densos, isso se deve a assimetr√≠a de nossos dados, isso pode levar a uma considera√ß√£o desigual dos vizinhos mais pr√≥ximos ao determinar-se o ponto que √© um outlier.

<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/DetectionIsolationKNN.png" width=90% height=80%>  
</p>

Uma vez detectados os outliers, procedi com a remo√ß√£o dos mesmos. Portanto, √© poss√≠vel observar nosso histograma e as estat√≠sticas ap√≥s a aplica√ß√£o do 4¬∫ m√©todo nas Figuras 15 e 16.
<p align="center">
  <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/histo_4tometodos.png" width=100% height=80%>  
   <img src="https://github.com/katherinGriffi/M-todos_extra-o_outliers/blob/main/imgs/estadisticas_4tometodo.JPG" width=80% height=80%>  
</p>

##### A extra√ß√£o de outliers pelo m√©todo k-NN teve um impacto positivo na redu√ß√£o da variabilidade dos dados
##### A distribui√ß√£o n√£o sim√©trica dos dados pode influenciar a detec√ß√£o de outliers pelo m√©todo k-NN, especialmente na defini√ß√£o de vizinhos pr√≥ximos.

## CONCLUS√ÉO
Ap√≥s analisar os resultados dos quatro m√©todos de detec√ß√£o de outliers (Intervalo Interquartil, Z-Core, Isolation Forest e KNN), podemos fazer as seguintes conclus√µes:

#### Compara√ß√£o de Desempenho:
A assimetria dos nossos dados pode influenciar a efic√°cia dos m√©todos que utilizamos para detec√ß√£o de outliers. Alguns m√©todos foram mais sens√≠veis aos valores extremos, como √© o caso dos m√©todos IQR, Isolation Forest e k-NN.

#### Impacto na M√©dia e Desvio Padr√£o:
Em distribui√ß√µes assim√©tricas, como √© o caso, a m√©dia e o desvio padr√£o est√£o sendo influenciados pelos valores extremos. Portanto, o m√©todo Z- core que utiliza estes par√°metros est√£o sendo afetados significativamente, isso podemos confirmar quando vemos o n√∫mero de outliers identificado por este m√©todo.

#### Percentual de Outliers:
- Os m√©todos IQR, Isolation Forest e k-NN, tiveram uma porcetagem proxima para detec√ß√£o de outliers em todos os niveis de suporte.
  
#### Escolha do m√©todo de extra√ß√£o de outliers:
- Debido a distribui√ß√£o assimetrica de nossos dados, podemos em primera isntancia descartar o m√©todo Z-core devido ao tipo de dsitribui√ß√£o.
- Debido a distribui√ß√£o asim√©trica dos dados, podemos descartar o a detec√ß√£o de outliers pelo m√©todo k-NN,  isso pode levar a uma considera√ß√£o desigual dos vizinhos mais pr√≥ximos ao determinar-se o ponto que √© um outlier.
- Tanto o Isolation Forest quanto o m√©todo do Intervalo Interquartil s√£o bons para extra√ß√£o de outliers para nosso dados assim√©tricos porque s√£o robustos, n√£o fazem suposi√ß√µes sobre a distribui√ß√£o dos dados e levam em considera√ß√£o a dispers√£o dos dados de forma eficaz. tanto o Isolation Forest quanto o m√©todo do Intervalo Interquartil s√£o bons para extra√ß√£o de outliers em dados assim√©tricos porque s√£o robustos, n√£o fazem suposi√ß√µes sobre a distribui√ß√£o dos dados e levam em considera√ß√£o a dispers√£o dos dados de forma eficaz.
 
